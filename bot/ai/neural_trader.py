# bot/ai/neural_trader.py
# –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π
# –§—É–Ω–∫—Ü–∏–∏: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞–≤–∫–∞–º–∏

import numpy as np
import pandas as pd
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import logging

class NeuralTrader:
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    
    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    - –í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π: —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ + —Å–∏–≥–Ω–∞–ª—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏–π (—Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π)
    - –°–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏: –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π
    - –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
    - –°–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è: reinforcement learning + —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
    """
    
    def __init__(self, 
                 input_size: int = 152,  # –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–û: —É–≤–µ–ª–∏—á–µ–Ω –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ö–≤–∞—Ç–∞ features
                 hidden_size: int = 64,   # –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–û: –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —É–≤–µ–ª–∏—á–µ–Ω
                 output_size: int = 10,
                 learning_rate: float = 0.001,
                 memory_size: int = 1000,
                 l2_lambda: float = 0.001,
                 dropout_rate: float = 0.15): # –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–û: —Å–Ω–∏–∂–µ–Ω –¥–ª—è –±–æ–ª—å—à–µ–π —Å–µ—Ç–∏
        
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.learning_rate = learning_rate
        self.memory_size = memory_size
        self.l2_lambda = l2_lambda
        self.dropout_rate = dropout_rate
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ (Xavier/Glorot)
        self.weights1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)
        self.weights2 = np.random.randn(hidden_size, hidden_size) * np.sqrt(2.0 / hidden_size)
        self.weights3 = np.random.randn(hidden_size, output_size) * np.sqrt(2.0 / hidden_size)
        
        # –°–º–µ—â–µ–Ω–∏—è
        self.bias1 = np.zeros((1, hidden_size))
        self.bias2 = np.zeros((1, hidden_size))
        self.bias3 = np.zeros((1, output_size))
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π learning rate
        self.initial_lr = learning_rate
        self.lr_decay = 0.95
        self.min_lr = 0.0001
        
        # Batch normalization –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.running_mean1 = np.zeros((1, hidden_size))
        self.running_var1 = np.ones((1, hidden_size))
        self.running_mean2 = np.zeros((1, hidden_size))
        self.running_var2 = np.ones((1, hidden_size))
        self.bn_momentum = 0.9
        
        # Early stopping
        self.best_loss = float('inf')
        self.patience = 10
        self.no_improve_count = 0
        
        # –ü–∞–º—è—Ç—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        self.memory = []
        self.performance_history = []
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        self.logger = logging.getLogger('neural_trader')
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_bets = 0
        self.winning_bets = 0
        self.current_balance = 1000.0
        self.bet_amount = 10.0
        self.max_bet_amount = 50.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–∞–≤–∫–∞
        self.min_bet_amount = 5.0   # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–∞–≤–∫–∞
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        self.prediction_accuracy = 0.0
        self.confidence_threshold = 0.6
        self.min_confidence = 0.5
        self.max_confidence = 0.95
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        self.load_model()
    
    def relu(self, x: np.ndarray) -> np.ndarray:
        """–§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ ReLU —Å –∫–ª–∏–ø–ø–∏–Ω–≥–æ–º"""
        return np.clip(np.maximum(0, x), 0, 10)  # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –≤–∑—Ä—ã–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    
    def relu_derivative(self, x: np.ndarray) -> np.ndarray:
        """–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è ReLU"""
        return np.where((x > 0) & (x < 10), 1, 0)
    
    def leaky_relu(self, x: np.ndarray, alpha: float = 0.01) -> np.ndarray:
        """Leaky ReLU –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
        return np.where(x > 0, x, alpha * x)
    
    def leaky_relu_derivative(self, x: np.ndarray, alpha: float = 0.01) -> np.ndarray:
        """–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è Leaky ReLU"""
        return np.where(x > 0, 1, alpha)
    
    def softmax(self, x: np.ndarray) -> np.ndarray:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Softmax —Å —á–∏—Å–ª–µ–Ω–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å—é"""
        # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ
        x_shifted = x - np.max(x, axis=1, keepdims=True)
        exp_x = np.exp(np.clip(x_shifted, -500, 500))
        return exp_x / (np.sum(exp_x, axis=1, keepdims=True) + 1e-8)
    
    def batch_normalize(self, x: np.ndarray, running_mean: np.ndarray, 
                       running_var: np.ndarray, training: bool = True) -> np.ndarray:
        """Batch normalization –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
        if training:
            batch_mean = np.mean(x, axis=0, keepdims=True)
            batch_var = np.var(x, axis=0, keepdims=True)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º running statistics
            running_mean[:] = (self.bn_momentum * running_mean + 
                             (1 - self.bn_momentum) * batch_mean)
            running_var[:] = (self.bn_momentum * running_var + 
                            (1 - self.bn_momentum) * batch_var)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            x_norm = (x - batch_mean) / np.sqrt(batch_var + 1e-8)
        else:
            x_norm = (x - running_mean) / np.sqrt(running_var + 1e-8)
        
        return x_norm
    
    def dropout(self, x: np.ndarray, training: bool = True) -> Tuple[np.ndarray, np.ndarray]:
        """Dropout –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
        if training and self.dropout_rate > 0:
            mask = np.random.binomial(1, 1 - self.dropout_rate, x.shape) / (1 - self.dropout_rate)
            return x * mask, mask
        return x, np.ones_like(x)
    
    def prepare_input_safe(self, market_data: Dict, strategy_signals: Dict) -> np.ndarray:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        features = []
        
        try:
            # –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
            timeframes = ['1m', '5m', '15m', '1h']
            for tf in timeframes:
                if tf in market_data and market_data[tf] is not None:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ DataFrame –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    tf_data = market_data[tf]
                    if isinstance(tf_data, dict):
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º dict –≤ DataFrame
                        try:
                            tf_data = pd.DataFrame(tf_data)
                        except Exception as e:
                            self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ {tf} –≤ DataFrame: {e}")
                            features.extend([0] * 8)
                            continue

                    if isinstance(tf_data, pd.DataFrame) and not tf_data.empty:
                        df = tf_data.tail(20).copy()  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ–∫–Ω–æ

                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
                        for col in ['open', 'high', 'low', 'close', 'volume']:
                            if col in df.columns:
                                df[col] = pd.to_numeric(df[col], errors='coerce')

                        # –£–±–∏—Ä–∞–µ–º NaN
                        df = df.dropna()

                        if len(df) > 5:  # –ú–∏–Ω–∏–º—É–º 5 —Å–≤–µ—á–µ–π –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
                            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                            close_prices = df['close'].values
                            volumes = df['volume'].values if 'volume' in df.columns else np.ones(len(df))

                            # –¶–µ–Ω–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
                            price_change = self._safe_divide(close_prices[-1] - close_prices[0], close_prices[0])
                            high_values = df['high'].values if 'high' in df.columns else close_prices
                            low_values = df['low'].values if 'low' in df.columns else close_prices
                            volatility = self._safe_divide(high_values.max() - low_values.min(), close_prices[-1])

                            # –û–±—ä–µ–º–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
                            volume_trend = self._safe_divide(volumes[-1], np.mean(volumes[:-1])) if len(volumes) > 1 else 1
                            volume_std = np.std(volumes) / (np.mean(volumes) + 1e-8)

                            # –¢—Ä–µ–Ω–¥–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
                            sma_5 = np.mean(close_prices[-5:])
                            sma_10 = np.mean(close_prices[-10:]) if len(close_prices) >= 10 else sma_5
                            trend_strength = self._safe_divide(sma_5 - sma_10, sma_10)

                            # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏ –º–æ–º–µ–Ω—Ç—É–º
                            returns = np.diff(close_prices) / close_prices[:-1]
                            volatility_std = np.std(returns) if len(returns) > 0 else 0
                            momentum = self._safe_divide(close_prices[-1] - close_prices[-3], close_prices[-3]) if len(close_prices) >= 3 else 0

                            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∫–ª–∏–ø–ø–∏–Ω–≥
                            features.extend([
                                np.clip(price_change, -0.2, 0.2),      # ¬±20%
                                np.clip(volatility, 0, 0.3),           # –î–æ 30%
                                np.clip(volume_trend, 0.1, 5.0),       # 0.1x - 5x
                                np.clip(volume_std, 0, 2.0),           # –î–æ 200%
                                np.clip(trend_strength, -0.1, 0.1),    # ¬±10%
                                np.clip(volatility_std, 0, 0.1),       # –î–æ 10%
                                np.clip(momentum, -0.1, 0.1),          # ¬±10%
                                1 if close_prices[-1] > close_prices[0] else 0  # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                            ])
                        else:
                            features.extend([0] * 8)
                    else:
                        features.extend([0] * 8)
                else:
                    features.extend([0] * 8)
            
            # üìà –†–ê–°–®–ò–†–ï–ù–ù–´–ï —Å–∏–≥–Ω–∞–ª—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏–π (—É–≤–µ–ª–∏—á–µ–Ω–æ —Å 4 –¥–æ 8 features)
            strategy_names = [f'strategy_{i:02d}' for i in range(1, 11)]
            for strategy_name in strategy_names:
                if strategy_name in strategy_signals:
                    signal = strategy_signals[strategy_name]
                    if signal and isinstance(signal, dict):
                        # –ö–æ–¥–∏—Ä—É–µ–º —Ç–∏–ø —Å–∏–≥–Ω–∞–ª–∞
                        signal_type = signal.get('signal', '')
                        if signal_type == 'BUY':
                            signal_value = 1.0
                        elif signal_type == 'SELL':
                            signal_value = -1.0
                        else:
                            signal_value = 0.0
                        
                        # –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω—ã –≤—Ö–æ–¥–∞
                        entry_price = float(signal.get('entry_price', 0))
                        current_price = self._get_current_price(market_data)
                        
                        price_deviation = 0
                        if current_price > 0 and entry_price > 0:
                            price_deviation = self._safe_divide(entry_price - current_price, current_price)
                            price_deviation = np.clip(price_deviation, -0.1, 0.1)  # ¬±10%
                        
                        # –ö–∞—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–∞
                        signal_strength = float(signal.get('signal_strength', 0.5))
                        signal_strength = np.clip(signal_strength, 0, 1)
                        
                        # Risk/Reward ratio
                        rr_ratio = float(signal.get('risk_reward_ratio', 1.0))
                        rr_ratio = np.clip(rr_ratio, 0.5, 5.0)  # –û—Ç 0.5 –¥–æ 5.0
                        rr_ratio_norm = (rr_ratio - 1.0) / 4.0  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ [-0.125, 1.0]
                        
                        # üìà –†–ê–°–®–ò–†–ï–ù–ù–´–ï features —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (4 ‚Üí 8)
                        stop_loss = float(signal.get('stop_loss', entry_price * 0.95))
                        take_profit = float(signal.get('take_profit', entry_price * 1.05))
                        time_decay = float(signal.get('time_in_position', 0)) / 3600  # —á–∞—Å—ã
                        confidence_decay = signal_strength * np.exp(-time_decay * 0.1)  # —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ
                        
                        features.extend([
                            signal_value, price_deviation, signal_strength, rr_ratio_norm,
                            np.clip(time_decay, 0, 24),  # –º–∞–∫—Å 24 —á–∞—Å–∞
                            np.clip(confidence_decay, 0, 1),  # –∑–∞—Ç—É—Ö–∞—é—â–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                            1 if signal_type == 'BUY' else (0.5 if signal_type == 'SELL' else 0),  # –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª  
                            np.clip(abs(price_deviation), 0, 0.1)  # –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
                        ])
                    else:
                        features.extend([0, 0, 0.5, 0, 0, 0.5, 0, 0])  # 8 –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö features
                else:
                    features.extend([0, 0, 0.5, 0, 0, 0.5, 0, 0])  # 8 –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö features
            
            # üî≠ –†–ê–°–®–ò–†–ï–ù–ù–´–ï —Ä—ã–Ω–æ—á–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (2 ‚Üí 16)
            market_sentiment = self._calculate_market_sentiment(market_data)
            volatility_index = self._calculate_volatility_index(market_data)
            trend_strength = self._calculate_trend_strength(market_data)
            momentum_divergence = self._calculate_momentum_divergence(market_data)
            volume_profile = self._calculate_volume_profile(market_data)
            correlation_matrix = self._calculate_timeframe_correlation(market_data)
            
            # –ú–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            spread_dynamics = self._calculate_spread_dynamics(market_data)
            order_flow_imbalance = self._calculate_order_flow_imbalance(market_data)
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
            time_features = self._extract_temporal_features()
            
            features.extend([
                # –û—Å–Ω–æ–≤–Ω—ã–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (6)
                np.clip(market_sentiment, -1, 1),
                np.clip(volatility_index, 0, 2),
                np.clip(trend_strength, -1, 1),
                np.clip(momentum_divergence, -1, 1),
                np.clip(volume_profile, 0, 2),
                np.clip(correlation_matrix, -1, 1),
                
                # –ú–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (2)
                np.clip(spread_dynamics, 0, 1),
                np.clip(order_flow_imbalance, -1, 1),
                
                # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã (8)
                *time_features
            ])
            
            # üö® –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –±–µ–∑ –ø–æ—Ç–µ—Ä—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏!
            # –¢–µ–ø–µ—Ä—å —Å–æ—Ö—Ä–∞–Ω—è–µ–º –í–°–ï features –±–µ–∑ –æ–±—Ä–µ–∑–∫–∏
            if len(features) < self.input_size:
                # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö
                padding_needed = self.input_size - len(features)
                features.extend([0.0] * padding_needed)
                self.logger.debug(f"–î–æ–ø–æ–ª–Ω–µ–Ω–æ {padding_needed} –Ω—É–ª–µ–≤—ã—Ö features")
            elif len(features) > self.input_size:
                # –õ–û–ì–ò–†–£–ï–ú –ü–†–û–ë–õ–ï–ú–£ - –Ω–µ –æ–±—Ä–µ–∑–∞–µ–º!
                excess_features = len(features) - self.input_size
                self.logger.warning(f"–ü–û–¢–ï–†–Ø –ò–ù–§–û–†–ú–ê–¶–ò–ò! {excess_features} features –æ–±—Ä–µ–∑–∞–Ω—ã")
                features = features[:self.input_size]
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –∏ Inf
            features = [0.0 if (np.isnan(f) or np.isinf(f)) else float(f) for f in features]
            
            return np.array(features, dtype=np.float32).reshape(1, -1)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä —Å –Ω–æ–≤—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
            return np.zeros((1, self.input_size), dtype=np.float32)
    
    def _safe_divide(self, a, b, default=0.0):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–µ–ª–µ–Ω–∏–µ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å"""
        try:
            if b == 0 or np.isnan(b) or np.isinf(b):
                return default
            result = a / b
            return result if not (np.isnan(result) or np.isinf(result)) else default
        except:
            return default
    
    def _get_current_price(self, market_data: Dict) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã –∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            for tf in ['1m', '5m', '15m', '1h']:
                if (tf in market_data and market_data[tf] is not None and 
                    not market_data[tf].empty):
                    return float(market_data[tf].iloc[-1]['close'])
        except:
            pass
        return 0.0
    
    def _calculate_market_sentiment(self, market_data: Dict) -> float:
        """–†–∞—Å—á–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è —Ä—ã–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤"""
        try:
            sentiment_scores = []
            
            for tf in ['5m', '15m', '1h']:
                if (tf in market_data and market_data[tf] is not None and 
                    not market_data[tf].empty):
                    df = market_data[tf].tail(10)
                    if len(df) > 1:
                        # –ü—Ä–æ—Å—Ç–æ–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è: —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–æ—Å—Ç–∞ –∫ –ø–∞–¥–µ–Ω–∏—é
                        price_changes = df['close'].pct_change().dropna()
                        if len(price_changes) > 0:
                            positive_changes = (price_changes > 0).sum()
                            total_changes = len(price_changes)
                            sentiment = (positive_changes / total_changes - 0.5) * 2  # –û—Ç -1 –¥–æ 1
                            sentiment_scores.append(sentiment)
            
            return np.mean(sentiment_scores) if sentiment_scores else 0.0
        except:
            return 0.0
    
    def _calculate_volatility_index(self, market_data: Dict) -> float:
        """–†–∞—Å—á–µ—Ç –∏–Ω–¥–µ–∫—Å–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            volatilities = []
            
            for tf in ['5m', '15m', '1h']:
                if (tf in market_data and market_data[tf] is not None and 
                    not market_data[tf].empty):
                    df = market_data[tf].tail(20)
                    if len(df) > 1:
                        returns = df['close'].pct_change().dropna()
                        if len(returns) > 0:
                            volatility = returns.std()
                            volatilities.append(volatility)
            
            return np.mean(volatilities) * 100 if volatilities else 0.0  # –í –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        except:
            return 0.0
    
    def forward_improved(self, x: np.ndarray, training: bool = True) -> Tuple[np.ndarray, Dict]:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏ dropout"""
        activations = {'input': x}
        
        try:
            # –ü–µ—Ä–≤—ã–π —Å–ª–æ–π
            z1 = np.dot(x, self.weights1) + self.bias1
            z1_norm = self.batch_normalize(z1, self.running_mean1, self.running_var1, training)
            a1 = self.leaky_relu(z1_norm)
            a1_drop, dropout_mask1 = self.dropout(a1, training)
            activations.update({'z1': z1, 'z1_norm': z1_norm, 'a1': a1, 'a1_drop': a1_drop, 'mask1': dropout_mask1})
            
            # –í—Ç–æ—Ä–æ–π —Å–ª–æ–π
            z2 = np.dot(a1_drop, self.weights2) + self.bias2
            z2_norm = self.batch_normalize(z2, self.running_mean2, self.running_var2, training)
            a2 = self.leaky_relu(z2_norm)
            a2_drop, dropout_mask2 = self.dropout(a2, training)
            activations.update({'z2': z2, 'z2_norm': z2_norm, 'a2': a2, 'a2_drop': a2_drop, 'mask2': dropout_mask2})
            
            # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
            z3 = np.dot(a2_drop, self.weights3) + self.bias3
            a3 = self.softmax(z3)
            activations.update({'z3': z3, 'a3': a3})
            
            return a3, activations
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä—è–º–æ–º –ø—Ä–æ—Ö–æ–¥–µ: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            uniform_output = np.ones((1, self.output_size)) / self.output_size
            return uniform_output, {'input': x}

    def predict(self, x: np.ndarray) -> np.ndarray:
        """
        –ü—É–±–ª–∏—á–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–æ–±–µ—Ä—Ç–∫–∞ –Ω–∞–¥ forward_improved)

        Args:
            x: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ shape (batch_size, input_size)

        Returns:
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è shape (batch_size, output_size)
        """
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if x is None:
                raise ValueError("–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å None")

            if not isinstance(x, np.ndarray):
                x = np.array(x, dtype=np.float32)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
            if len(x.shape) == 1:
                x = x.reshape(1, -1)

            if x.shape[1] != self.input_size:
                self.logger.warning(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {x.shape[1]}, –æ–∂–∏–¥–∞–ª—Å—è: {self.input_size}")
                # –û–±—Ä–µ–∑–∞–µ–º –∏–ª–∏ –¥–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
                if x.shape[1] > self.input_size:
                    x = x[:, :self.input_size]
                else:
                    x = np.pad(x, ((0, 0), (0, self.input_size - x.shape[1])), mode='constant')

            # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (inference mode)
            prediction, _ = self.forward_improved(x, training=False)

            return prediction

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            return np.ones((1, self.output_size)) / self.output_size

    def predict_strategy_performance(self, market_data: Dict, strategy_signals: Dict) -> Dict[str, float]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        try:
            x = self.prepare_input_safe(market_data, strategy_signals)
            predictions, _ = self.forward_improved(x, training=False)
            
            strategy_names = [f'strategy_{i:02d}' for i in range(1, 11)]
            results = {}
            
            for i, strategy_name in enumerate(strategy_names):
                if i < len(predictions[0]):
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                    confidence = float(predictions[0][i])
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏
                    confidence = np.clip(confidence, self.min_confidence, self.max_confidence)
                    results[strategy_name] = confidence
                else:
                    results[strategy_name] = 0.5  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            
            return results
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            strategy_names = [f'strategy_{i:02d}' for i in range(1, 11)]
            return {name: 0.5 for name in strategy_names}
    
    def make_bet(self, market_data: Dict, strategy_signals: Dict) -> Optional[Dict]:
        """–ü—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å—Ç–∞–≤–∫–µ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–æ–º"""
        try:
            predictions = self.predict_strategy_performance(market_data, strategy_signals)
            
            if not predictions:
                return None
            
            # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
            best_strategy = max(predictions.items(), key=lambda x: x[1])
            strategy_name, confidence = best_strategy
            
            # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            dynamic_threshold = self._calculate_dynamic_threshold()
            
            if confidence > dynamic_threshold:
                # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä —Å—Ç–∞–≤–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                bet_size = self._calculate_bet_size(confidence)
                
                bet = {
                    'strategy': strategy_name,
                    'confidence': confidence,
                    'timestamp': datetime.now().isoformat(),
                    'bet_amount': bet_size,
                    'threshold_used': dynamic_threshold,
                    'all_predictions': predictions,
                    'market_data': self._serialize_market_data(market_data)
                }
                
                self.total_bets += 1
                self.logger.info(f"–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å—Ç–∞–≤–∫–∞: {strategy_name} "
                               f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.3f}, —Ä–∞–∑–º–µ—Ä: ${bet_size:.2f})")
                
                return bet
            else:
                self.logger.debug(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.3f} –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞ {dynamic_threshold:.3f}")
                return None
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è –æ —Å—Ç–∞–≤–∫–µ: {e}")
            return None
    
    def _calculate_dynamic_threshold(self) -> float:
        """–†–∞—Å—á–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø–æ—Ä–æ–≥–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        try:
            if self.total_bets == 0:
                return self.confidence_threshold
            
            win_rate = self.winning_bets / self.total_bets
            
            # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥: –µ—Å–ª–∏ –≤–∏–Ω—Ä–µ–π—Ç –≤—ã—Å–æ–∫–∏–π - —Å–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥, –µ—Å–ª–∏ –Ω–∏–∑–∫–∏–π - –ø–æ–≤—ã—à–∞–µ–º
            if win_rate > 0.6:
                # –•–æ—Ä–æ—à–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –º–æ–∂–µ–º –±—ã—Ç—å –º–µ–Ω–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–º–∏
                threshold = max(0.55, self.confidence_threshold - 0.1)
            elif win_rate < 0.4:
                # –ü–ª–æ—Ö–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å - —Å—Ç–∞–Ω–æ–≤–∏–º—Å—è –±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–º–∏
                threshold = min(0.8, self.confidence_threshold + 0.1)
            else:
                threshold = self.confidence_threshold
            
            return threshold
            
        except:
            return self.confidence_threshold
    
    def _calculate_bet_size(self, confidence: float) -> float:
        """–†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ —Å—Ç–∞–≤–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Ç–µ–∫—É—â–µ–≥–æ –±–∞–ª–∞–Ω—Å–∞"""
        try:
            # Kelly Criterion inspired sizing
            base_fraction = 0.02  # 2% –æ—Ç –±–∞–ª–∞–Ω—Å–∞ –∫–∞–∫ –±–∞–∑–∞
            confidence_multiplier = (confidence - 0.5) * 2  # –û—Ç 0 –¥–æ 1
            
            # –£—á–∏—Ç—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            if self.total_bets > 10:
                win_rate = self.winning_bets / self.total_bets
                performance_multiplier = min(2.0, max(0.5, win_rate * 2))
            else:
                performance_multiplier = 1.0
            
            # –†–∞–∑–º–µ—Ä —Å—Ç–∞–≤–∫–∏ –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –±–∞–ª–∞–Ω—Å–∞
            fraction = base_fraction * confidence_multiplier * performance_multiplier
            bet_size = self.current_balance * fraction
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Å—Ç–∞–≤–∫–∏
            bet_size = np.clip(bet_size, self.min_bet_amount, self.max_bet_amount)
            
            return round(bet_size, 2)
            
        except:
            return self.bet_amount
    
    def _serialize_market_data(self, market_data: Dict) -> Dict:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        try:
            serialized = {}
            for tf, df in market_data.items():
                if df is not None and not df.empty:
                    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–≤–µ—á—É –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞
                    last_candle = df.iloc[-1].to_dict()
                    serialized[tf] = last_candle
                else:
                    serialized[tf] = {}
            return serialized
        except:
            return {}
    
    def update_performance(self, bet: Dict, result: Dict):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π"""
        if not bet:
            return
        
        try:
            strategy_name = bet['strategy']
            success = result.get('success', False)
            profit = result.get('profit', 0)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            if success:
                self.winning_bets += 1
                self.current_balance += profit
                reward = 1.0
            else:
                self.current_balance = max(0, self.current_balance - bet['bet_amount'])
                reward = -1.0
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            performance_record = {
                'timestamp': datetime.now().isoformat(),
                'strategy': strategy_name,
                'confidence': bet['confidence'],
                'bet_amount': bet['bet_amount'],
                'success': success,
                'profit': profit,
                'balance': self.current_balance,
                'win_rate': self.winning_bets / self.total_bets if self.total_bets > 0 else 0
            }
            self.performance_history.append(performance_record)
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
            if len(self.performance_history) > 1000:
                self.performance_history = self.performance_history[-1000:]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø—ã—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            experience = {
                'bet': bet,
                'result': result,
                'reward': reward,
                'timestamp': datetime.now().isoformat()
            }
            
            self.memory.append(experience)
            if len(self.memory) > self.memory_size:
                self.memory.pop(0)
            
            # –û–±—É—á–∞–µ–º –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å
            if len(self.memory) >= 10:
                self.train_with_validation()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            self.save_model()
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            win_rate = (self.winning_bets / self.total_bets * 100) if self.total_bets > 0 else 0
            roi = ((self.current_balance - 1000.0) / 1000.0 * 100)
            
            self.logger.info(f"–°—Ç–∞–≤–∫–∞ {'‚úÖ —É—Å–ø–µ—à–Ω–∞' if success else '‚ùå –Ω–µ—É—Å–ø–µ—à–Ω–∞'}. "
                           f"–ë–∞–ª–∞–Ω—Å: ${self.current_balance:.2f}, "
                           f"–í–∏–Ω—Ä–µ–π—Ç: {win_rate:.1f}%, ROI: {roi:.1f}%")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
    
    def train_with_validation(self, train_ratio: float = 0.8):
        """–û–±—É—á–µ–Ω–∏–µ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–æ–π –∏ early stopping"""
        try:
            if len(self.memory) < 20:
                return
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
            experiences = self.memory.copy()
            np.random.shuffle(experiences)
            
            split_idx = int(len(experiences) * train_ratio)
            train_exp = experiences[:split_idx]
            val_exp = experiences[split_idx:]
            
            # –û–±—É—á–∞–µ–º –Ω–∞ train –¥–∞–Ω–Ω—ã—Ö
            train_loss = self._train_batch(train_exp, training=True)
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –Ω–∞ validation –¥–∞–Ω–Ω—ã—Ö
            val_loss = self._train_batch(val_exp, training=False)
            
            # Early stopping –∏ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π learning rate
            if val_loss < self.best_loss:
                self.best_loss = val_loss
                self.no_improve_count = 0
            else:
                self.no_improve_count += 1
                if self.no_improve_count >= self.patience:
                    # –°–Ω–∏–∂–∞–µ–º learning rate
                    self.learning_rate = max(self.learning_rate * self.lr_decay, self.min_lr)
                    self.no_improve_count = 0
                    self.logger.info(f"Learning rate —Å–Ω–∏–∂–µ–Ω –¥–æ {self.learning_rate:.6f}")
            
            self.logger.debug(f"Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
    
    def _train_batch(self, experiences: List, training: bool = True) -> float:
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –±–∞—Ç—á–µ –¥–∞–Ω–Ω—ã—Ö"""
        if not experiences:
            return 0.0
        
        total_loss = 0
        successful_updates = 0
        
        for experience in experiences:
            try:
                bet = experience['bet']
                reward = experience['reward']
                
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                market_data_df = self._deserialize_market_data(bet.get('market_data', {}))
                strategy_signals = {bet['strategy']: {'signal': 'BUY'}}
                
                x = self.prepare_input_safe(market_data_df, strategy_signals)
                predictions, activations = self.forward_improved(x, training=training)
                
                # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å soft targets
                target = np.full((1, self.output_size), 0.1)  # –ë–∞–∑–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                strategy_names = [f'strategy_{i:02d}' for i in range(1, 11)]
                
                if bet['strategy'] in strategy_names:
                    strategy_index = strategy_names.index(bet['strategy'])
                    if strategy_index < self.output_size:
                        if reward > 0:
                            target[0, strategy_index] = 0.9  # –£—Å–ø–µ—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
                        else:
                            target[0, strategy_index] = 0.1  # –ù–µ—É—Å–ø–µ—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
                
                # –í—ã—á–∏—Å–ª—è–µ–º loss —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π
                loss = self._calculate_loss_with_regularization(predictions, target)
                total_loss += loss
                
                # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –¥–ª—è training
                if training:
                    self._backpropagate_improved(x, target, activations)
                
                successful_updates += 1
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ–ø—ã—Ç–µ: {e}")
                continue
        
        return total_loss / successful_updates if successful_updates > 0 else 0.0
    
    def _deserialize_market_data(self, serialized_data: Dict) -> Dict:
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞"""
        try:
            market_data_df = {}
            for tf, data in serialized_data.items():
                if data and isinstance(data, dict):
                    market_data_df[tf] = pd.DataFrame([data])
                else:
                    market_data_df[tf] = pd.DataFrame()
            return market_data_df
        except:
            return {}
    
    def _calculate_loss_with_regularization(self, predictions: np.ndarray, targets: np.ndarray) -> float:
        """–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å —Å L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π"""
        try:
            # Cross-entropy loss
            ce_loss = -np.mean(targets * np.log(predictions + 1e-8))
            
            # L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
            l2_loss = (self.l2_lambda * (np.sum(self.weights1**2) + 
                                        np.sum(self.weights2**2) + 
                                        np.sum(self.weights3**2)))
            
            return ce_loss + l2_loss
        except:
            return 1.0
    
    def _backpropagate_improved(self, x: np.ndarray, target: np.ndarray, activations: Dict):
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–º –∫–ª–∏–ø–ø–∏–Ω–≥–æ–º"""
        try:
            a3 = activations.get('a3')
            a2_drop = activations.get('a2_drop')
            a1_drop = activations.get('a1_drop')
            z2_norm = activations.get('z2_norm')
            z1_norm = activations.get('z1_norm')
            
            if any(v is None for v in [a3, a2_drop, a1_drop, z2_norm, z1_norm]):
                return
            
            # –û—à–∏–±–∫–∞ –Ω–∞ –≤—ã—Ö–æ–¥–Ω–æ–º —Å–ª–æ–µ
            error3 = a3 - target
            delta3 = error3
            
            # –û—à–∏–±–∫–∞ –Ω–∞ –≤—Ç–æ—Ä–æ–º —Å–ª–æ–µ
            error2 = np.dot(delta3, self.weights3.T)
            delta2 = error2 * self.leaky_relu_derivative(z2_norm)
            
            # –û—à–∏–±–∫–∞ –Ω–∞ –ø–µ—Ä–≤–æ–º —Å–ª–æ–µ
            error1 = np.dot(delta2, self.weights2.T)
            delta1 = error1 * self.leaky_relu_derivative(z1_norm)
            
            # –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–µ –∫–ª–∏–ø–ø–∏–Ω–≥
            delta3 = np.clip(delta3, -1, 1)
            delta2 = np.clip(delta2, -1, 1)
            delta1 = np.clip(delta1, -1, 1)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ —Å L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π
            self.weights3 -= self.learning_rate * (np.dot(a2_drop.T, delta3) + 
                                                  self.l2_lambda * self.weights3)
            self.bias3 -= self.learning_rate * np.sum(delta3, axis=0, keepdims=True)
            
            self.weights2 -= self.learning_rate * (np.dot(a1_drop.T, delta2) + 
                                                  self.l2_lambda * self.weights2)
            self.bias2 -= self.learning_rate * np.sum(delta2, axis=0, keepdims=True)
            
            self.weights1 -= self.learning_rate * (np.dot(x.T, delta1) + 
                                                  self.l2_lambda * self.weights1)
            self.bias1 -= self.learning_rate * np.sum(delta1, axis=0, keepdims=True)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
    
    def get_advanced_statistics(self) -> Dict:
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            base_stats = self.get_statistics()
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            recent_performance = self.performance_history[-50:] if len(self.performance_history) >= 50 else self.performance_history
            
            if recent_performance:
                recent_win_rate = sum(1 for p in recent_performance if p['success']) / len(recent_performance)
                recent_avg_profit = np.mean([p['profit'] for p in recent_performance])
                recent_avg_confidence = np.mean([p['confidence'] for p in recent_performance])
                
                # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º
                strategy_performance = {}
                for perf in recent_performance:
                    strategy = perf['strategy']
                    if strategy not in strategy_performance:
                        strategy_performance[strategy] = {'wins': 0, 'total': 0, 'profits': []}
                    
                    strategy_performance[strategy]['total'] += 1
                    if perf['success']:
                        strategy_performance[strategy]['wins'] += 1
                    strategy_performance[strategy]['profits'].append(perf['profit'])
                
                # –†–∞—Å—á–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º
                for strategy, data in strategy_performance.items():
                    data['win_rate'] = data['wins'] / data['total'] if data['total'] > 0 else 0
                    data['avg_profit'] = np.mean(data['profits']) if data['profits'] else 0
                    data['total_profit'] = sum(data['profits'])
            else:
                recent_win_rate = 0
                recent_avg_profit = 0
                recent_avg_confidence = 0.5
                strategy_performance = {}
            
            # –†–∞—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏
            balance_history = [p['balance'] for p in self.performance_history]
            max_drawdown = self._calculate_max_drawdown(balance_history)
            
            # –ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏
            prediction_accuracy = self._calculate_prediction_accuracy()
            
            advanced_stats = {
                **base_stats,
                'recent_performance': {
                    'win_rate': recent_win_rate * 100,
                    'avg_profit': recent_avg_profit,
                    'avg_confidence': recent_avg_confidence,
                    'samples': len(recent_performance)
                },
                'strategy_breakdown': strategy_performance,
                'risk_metrics': {
                    'max_drawdown': max_drawdown,
                    'current_drawdown': self._calculate_current_drawdown(balance_history),
                    'volatility': self._calculate_balance_volatility(balance_history)
                },
                'model_quality': {
                    'prediction_accuracy': prediction_accuracy,
                    'learning_rate': self.learning_rate,
                    'memory_usage': len(self.memory),
                    'training_cycles': len(self.performance_history)
                }
            }
            
            return advanced_stats
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return self.get_statistics()
    
    def _calculate_max_drawdown(self, balance_history: List[float]) -> float:
        """–†–∞—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏"""
        if not balance_history:
            return 0.0
        
        try:
            peak = balance_history[0]
            max_drawdown = 0.0
            
            for balance in balance_history:
                if balance > peak:
                    peak = balance
                drawdown = (peak - balance) / peak if peak > 0 else 0
                max_drawdown = max(max_drawdown, drawdown)
            
            return max_drawdown * 100  # –í –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        except:
            return 0.0
    
    def _calculate_current_drawdown(self, balance_history: List[float]) -> float:
        """–†–∞—Å—á–µ—Ç —Ç–µ–∫—É—â–µ–π –ø—Ä–æ—Å–∞–¥–∫–∏"""
        if not balance_history:
            return 0.0
        
        try:
            peak = max(balance_history)
            current = balance_history[-1]
            return ((peak - current) / peak * 100) if peak > 0 else 0.0
        except:
            return 0.0
    
    def _calculate_balance_volatility(self, balance_history: List[float]) -> float:
        """–†–∞—Å—á–µ—Ç –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –±–∞–ª–∞–Ω—Å–∞"""
        if len(balance_history) < 2:
            return 0.0
        
        try:
            returns = [balance_history[i] / balance_history[i-1] - 1 
                      for i in range(1, len(balance_history)) 
                      if balance_history[i-1] > 0]
            return np.std(returns) * 100 if returns else 0.0  # –í –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        except:
            return 0.0
    
    def _calculate_prediction_accuracy(self) -> float:
        """–†–∞—Å—á–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        try:
            if len(self.performance_history) < 10:
                return 0.5
            
            recent = self.performance_history[-100:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–∞–ø–∏—Å–µ–π
            correct_predictions = 0
            
            for record in recent:
                # –°—á–∏—Ç–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º, –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –±—ã–ª–∞ –≤—ã—Å–æ–∫–æ–π –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É—Å–ø–µ—à–Ω—ã–π
                # –∏–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –±—ã–ª–∞ –Ω–∏–∑–∫–æ–π –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ—É—Å–ø–µ—à–Ω—ã–π
                confidence = record['confidence']
                success = record['success']
                
                if (confidence > 0.6 and success) or (confidence <= 0.6 and not success):
                    correct_predictions += 1
            
            return correct_predictions / len(recent)
        except:
            return 0.5
    
    def get_statistics(self) -> Dict:
        """–ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        try:
            win_rate = (self.winning_bets / self.total_bets * 100) if self.total_bets > 0 else 0
            roi = ((self.current_balance - 1000.0) / 1000.0 * 100) if self.current_balance > 0 else -100
            
            return {
                'total_bets': self.total_bets,
                'winning_bets': self.winning_bets,
                'win_rate': win_rate,
                'current_balance': self.current_balance,
                'profit': self.current_balance - 1000.0,
                'roi': roi,
                'avg_bet_size': self.bet_amount,
                'confidence_threshold': self.confidence_threshold,
                'memory_size': len(self.memory),
                'model_version': '2.0'
            }
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {
                'total_bets': 0,
                'winning_bets': 0,
                'win_rate': 0,
                'current_balance': 1000.0,
                'profit': 0,
                'roi': 0
            }
    
    def save_model(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            model_data = {
                'version': '2.0',
                'timestamp': datetime.now().isoformat(),
                'architecture': {
                    'input_size': self.input_size,
                    'hidden_size': self.hidden_size,
                    'output_size': self.output_size
                },
                'weights': {
                    'weights1': self.weights1.tolist(),
                    'weights2': self.weights2.tolist(),
                    'weights3': self.weights3.tolist(),
                    'bias1': self.bias1.tolist(),
                    'bias2': self.bias2.tolist(),
                    'bias3': self.bias3.tolist()
                },
                'batch_norm': {
                    'running_mean1': self.running_mean1.tolist(),
                    'running_var1': self.running_var1.tolist(),
                    'running_mean2': self.running_mean2.tolist(),
                    'running_var2': self.running_var2.tolist()
                },
                'hyperparameters': {
                    'learning_rate': self.learning_rate,
                    'l2_lambda': self.l2_lambda,
                    'dropout_rate': self.dropout_rate,
                    'confidence_threshold': self.confidence_threshold
                },
                'statistics': {
                    'total_bets': self.total_bets,
                    'winning_bets': self.winning_bets,
                    'current_balance': self.current_balance,
                    'best_loss': self.best_loss
                },
                'performance_history': self.performance_history[-100:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–∞–ø–∏—Å–µ–π
            }
            
            os.makedirs('data/ai', exist_ok=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å
            with open('data/ai/neural_trader_model.json', 'w') as f:
                json.dump(model_data, f, indent=2)
            
            # –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
            backup_filename = f"data/ai/neural_trader_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(backup_filename, 'w') as f:
                json.dump(model_data, f)
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5)
            self._cleanup_old_backups()
            
            self.logger.debug("–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
    
    def _cleanup_old_backups(self):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤ –º–æ–¥–µ–ª–∏"""
        try:
            import glob
            backup_files = glob.glob('data/ai/neural_trader_backup_*.json')
            backup_files.sort()  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ (–ø–æ –≤—Ä–µ–º–µ–Ω–∏)
            
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5
            for old_backup in backup_files[:-5]:
                try:
                    os.remove(old_backup)
                except:
                    pass
        except:
            pass
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        model_path = 'data/ai/neural_trader_model.json'
        
        if not os.path.exists(model_path):
            self.logger.info("–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é")
            return
        
        try:
            with open(model_path, 'r') as f:
                model_data = json.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏
            version = model_data.get('version', '1.0')
            if version != '2.0':
                self.logger.warning(f"–ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –º–æ–¥–µ–ª—å –≤–µ—Ä—Å–∏–∏ {version}, –æ–∂–∏–¥–∞–ª–∞—Å—å 2.0")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
            weights = model_data.get('weights', {})
            if weights:
                self.weights1 = np.array(weights['weights1'])
                self.weights2 = np.array(weights['weights2'])
                self.weights3 = np.array(weights['weights3'])
                self.bias1 = np.array(weights['bias1'])
                self.bias2 = np.array(weights['bias2'])
                self.bias3 = np.array(weights['bias3'])
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º batch normalization –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            batch_norm = model_data.get('batch_norm', {})
            if batch_norm:
                self.running_mean1 = np.array(batch_norm.get('running_mean1', self.running_mean1))
                self.running_var1 = np.array(batch_norm.get('running_var1', self.running_var1))
                self.running_mean2 = np.array(batch_norm.get('running_mean2', self.running_mean2))
                self.running_var2 = np.array(batch_norm.get('running_var2', self.running_var2))
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            hyperparams = model_data.get('hyperparameters', {})
            if hyperparams:
                self.learning_rate = hyperparams.get('learning_rate', self.learning_rate)
                self.l2_lambda = hyperparams.get('l2_lambda', self.l2_lambda)
                self.dropout_rate = hyperparams.get('dropout_rate', self.dropout_rate)
                self.confidence_threshold = hyperparams.get('confidence_threshold', self.confidence_threshold)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            statistics = model_data.get('statistics', {})
            if statistics:
                self.total_bets = statistics.get('total_bets', 0)
                self.winning_bets = statistics.get('winning_bets', 0)
                self.current_balance = statistics.get('current_balance', 1000.0)
                self.best_loss = statistics.get('best_loss', float('inf'))
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            self.performance_history = model_data.get('performance_history', [])
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            self._validate_loaded_model()
            
            win_rate = (self.winning_bets / self.total_bets * 100) if self.total_bets > 0 else 0
            self.logger.info(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: –ë–∞–ª–∞–Ω—Å ${self.current_balance:.2f}, "
                           f"–°—Ç–∞–≤–æ–∫: {self.total_bets}, –í–∏–Ω—Ä–µ–π—Ç: {win_rate:.1f}%")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            self.logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é")
    
    def _validate_loaded_model(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤–µ—Å–æ–≤
            assert self.weights1.shape == (self.input_size, self.hidden_size)
            assert self.weights2.shape == (self.hidden_size, self.hidden_size)
            assert self.weights3.shape == (self.hidden_size, self.output_size)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN –∏ Inf
            for weights in [self.weights1, self.weights2, self.weights3]:
                if np.any(np.isnan(weights)) or np.any(np.isinf(weights)):
                    raise ValueError("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN –∏–ª–∏ Inf –≤ –≤–µ—Å–∞—Ö")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π
            if self.current_balance < 0 or self.current_balance > 1000000:
                self.logger.warning(f"–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞: {self.current_balance}")
                self.current_balance = max(0, min(self.current_balance, 10000))
            
            if self.total_bets < 0 or self.winning_bets < 0 or self.winning_bets > self.total_bets:
                self.logger.warning("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ç–∞–≤–æ–∫, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º")
                self.total_bets = 0
                self.winning_bets = 0
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ—Å–∞ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            self.__init__(self.input_size, self.hidden_size, self.output_size, 
                         self.initial_lr, self.memory_size, self.l2_lambda, self.dropout_rate)
    
    def reset_model(self):
        """–°–±—Ä–æ—Å –º–æ–¥–µ–ª–∏ –∫ –Ω–∞—á–∞–ª—å–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é"""
        self.logger.info("–°–±—Ä–æ—Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∫ –Ω–∞—á–∞–ª—å–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é")
        
        # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ—Å–∞
        self.weights1 = np.random.randn(self.input_size, self.hidden_size) * np.sqrt(2.0 / self.input_size)
        self.weights2 = np.random.randn(self.hidden_size, self.hidden_size) * np.sqrt(2.0 / self.hidden_size)
        self.weights3 = np.random.randn(self.hidden_size, self.output_size) * np.sqrt(2.0 / self.hidden_size)
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–º–µ—â–µ–Ω–∏—è
        self.bias1 = np.zeros((1, self.hidden_size))
        self.bias2 = np.zeros((1, self.hidden_size))
        self.bias3 = np.zeros((1, self.output_size))
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º batch normalization
        self.running_mean1 = np.zeros((1, self.hidden_size))
        self.running_var1 = np.ones((1, self.hidden_size))
        self.running_mean2 = np.zeros((1, self.hidden_size))
        self.running_var2 = np.ones((1, self.hidden_size))
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.total_bets = 0
        self.winning_bets = 0
        self.current_balance = 1000.0
        self.memory = []
        self.performance_history = []
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
        self.learning_rate = self.initial_lr
        self.best_loss = float('inf')
        self.no_improve_count = 0
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–±—Ä–æ—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        self.save_model()
    
    def _calculate_trend_strength(self, market_data: Dict) -> float:
        """–†–∞—Å—á–µ—Ç —Å–∏–ª—ã —Ç—Ä–µ–Ω–¥–∞ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º"""
        try:
            trend_signals = []
            for tf in ['5m', '15m', '1h']:
                if (tf in market_data and market_data[tf] is not None and not market_data[tf].empty):
                    df = market_data[tf].tail(50)
                    if len(df) >= 20:
                        # ADX-like trend strength
                        high, low, close = df['high'], df['low'], df['close']
                        plus_dm = np.maximum(high.diff(), 0)
                        minus_dm = np.maximum(-low.diff(), 0)
                        tr = np.maximum(high - low, np.maximum(abs(high - close.shift()), abs(low - close.shift())))
                        
                        plus_di = 100 * (plus_dm.rolling(14).mean() / tr.rolling(14).mean())
                        minus_di = 100 * (minus_dm.rolling(14).mean() / tr.rolling(14).mean())
                        dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di)
                        adx = dx.rolling(14).mean().iloc[-1]
                        
                        if not np.isnan(adx):
                            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º ADX –æ—Ç 0-100 –∫ -1,1
                            trend_direction = 1 if plus_di.iloc[-1] > minus_di.iloc[-1] else -1
                            trend_signals.append(trend_direction * (adx / 100))
            
            return np.mean(trend_signals) if trend_signals else 0.0
        except:
            return 0.0
    
    def _calculate_momentum_divergence(self, market_data: Dict) -> float:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏–π –º–æ–º–µ–Ω—Ç—É–º–∞"""
        try:
            for tf in ['15m', '1h']:
                if (tf in market_data and market_data[tf] is not None and not market_data[tf].empty):
                    df = market_data[tf].tail(50)
                    if len(df) >= 14:
                        close = df['close']
                        # RSI calculation
                        delta = close.diff()
                        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
                        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
                        rs = gain / loss
                        rsi = 100 - (100 / (1 + rs))
                        
                        # –ü—Ä–æ—Å—Ç–∞—è –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏ RSI
                        price_trend = (close.iloc[-1] - close.iloc[-10]) / close.iloc[-10]
                        rsi_trend = (rsi.iloc[-1] - rsi.iloc[-10]) / 100
                        
                        # –î–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è: –∫–æ–≥–¥–∞ —Ü–µ–Ω–∞ –∏ RSI –¥–≤–∏–∂—É—Ç—Å—è –≤ —Ä–∞–∑–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
                        if (price_trend > 0 and rsi_trend < 0) or (price_trend < 0 and rsi_trend > 0):
                            return abs(price_trend - rsi_trend)  # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è
                        else:
                            return 0.0
            return 0.0
        except:
            return 0.0
    
    def _calculate_volume_profile(self, market_data: Dict) -> float:
        """–ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–º–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è"""
        try:
            for tf in ['5m', '15m']:
                if (tf in market_data and market_data[tf] is not None and not market_data[tf].empty):
                    df = market_data[tf].tail(100)
                    if len(df) >= 20:
                        # VWAP –∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç –Ω–µ–≥–æ
                        typical_price = (df['high'] + df['low'] + df['close']) / 3
                        vwap = (typical_price * df['volume']).sum() / df['volume'].sum()
                        current_price = df['close'].iloc[-1]
                        
                        # On-Balance Volume trend
                        obv = np.where(df['close'] > df['close'].shift(1), df['volume'], 
                                      np.where(df['close'] < df['close'].shift(1), -df['volume'], 0)).cumsum()
                        obv_trend = (obv[-1] - obv[-10]) / (abs(obv[-10]) + 1e-8)
                        
                        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º VWAP –¥–∏—Å—Ç–∞–Ω—Ü–∏—é –∏ OBV —Ç—Ä–µ–Ω–¥
                        vwap_distance = (current_price - vwap) / vwap
                        return np.clip(abs(vwap_distance) + abs(obv_trend) * 0.1, 0, 2)
            return 0.0
        except:
            return 0.0
    
    def _calculate_timeframe_correlation(self, market_data: Dict) -> float:
        """–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º–∏"""
        try:
            timeframes = ['5m', '15m', '1h']
            returns_data = []
            
            for tf in timeframes:
                if (tf in market_data and market_data[tf] is not None and not market_data[tf].empty):
                    df = market_data[tf].tail(50)
                    if len(df) > 1:
                        returns = df['close'].pct_change().dropna()
                        if len(returns) >= 10:
                            returns_data.append(returns.iloc[-10:].values)  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –≤–æ–∑–≤—Ä–∞—Ç–æ–≤
            
            if len(returns_data) >= 2:
                # –°—Ä–µ–¥–Ω—è—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –≤—Å–µ–º–∏ –ø–∞—Ä–∞–º–∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
                correlations = []
                for i in range(len(returns_data)):
                    for j in range(i + 1, len(returns_data)):
                        min_len = min(len(returns_data[i]), len(returns_data[j]))
                        if min_len > 3:
                            corr = np.corrcoef(returns_data[i][:min_len], returns_data[j][:min_len])[0, 1]
                            if not np.isnan(corr):
                                correlations.append(corr)
                
                return np.mean(correlations) if correlations else 0.0
            return 0.0
        except:
            return 0.0
    
    def _calculate_spread_dynamics(self, market_data: Dict) -> float:
        """–î–∏–Ω–∞–º–∏–∫–∞ —Å–ø—Ä–µ–¥–∞ (bid-ask)"""
        try:
            # –ü—Ä–∏–±–ª–∏–∂–∞–µ–º —Å–ø—Ä–µ–¥ —á–µ—Ä–µ–∑ high-low –≤ –º–∏–Ω—É—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            for tf in ['1m', '5m']:
                if (tf in market_data and market_data[tf] is not None and not market_data[tf].empty):
                    df = market_data[tf].tail(20)
                    if len(df) > 1:
                        spreads = (df['high'] - df['low']) / df['close']
                        spread_volatility = spreads.std()
                        avg_spread = spreads.mean()
                        return np.clip(avg_spread + spread_volatility, 0, 1)
            return 0.5
        except:
            return 0.5
    
    def _calculate_order_flow_imbalance(self, market_data: Dict) -> float:
        """–ù–µ–±–∞–ª–∞–Ω—Å –æ—Ä–¥–µ—Ä—Ñ–ª–æ—É (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)"""
        try:
            for tf in ['1m', '5m']:
                if (tf in market_data and market_data[tf] is not None and not market_data[tf].empty):
                    df = market_data[tf].tail(20)
                    if len(df) > 1:
                        # –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –æ–±—ä–µ–º –Ω–∞ —Ä–æ—Å—Ç–µ –∏ –ø–∞–¥–µ–Ω–∏–∏
                        up_volume = df[df['close'] > df['open']]['volume'].sum()
                        down_volume = df[df['close'] < df['open']]['volume'].sum()
                        total_volume = up_volume + down_volume
                        
                        if total_volume > 0:
                            imbalance = (up_volume - down_volume) / total_volume
                            return np.clip(imbalance, -1, 1)
            return 0.0
        except:
            return 0.0
    
    def _extract_temporal_features(self) -> List[float]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        try:
            now = datetime.now()
            
            # –¶–∏–∫–ª–∏—á–µ—Å–∫–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ (—Å–∏–Ω—É—Å –∏ –∫–æ—Å–∏–Ω—É—Å)
            hour_sin = np.sin(2 * np.pi * now.hour / 24)
            hour_cos = np.cos(2 * np.pi * now.hour / 24)
            
            day_of_week_sin = np.sin(2 * np.pi * now.weekday() / 7)
            day_of_week_cos = np.cos(2 * np.pi * now.weekday() / 7)
            
            # –¢–æ—Ä–≥–æ–≤—ã–µ —Å–µ—Å—Å–∏–∏ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
            asian_session = 1.0 if 0 <= now.hour <= 8 else 0.0
            european_session = 1.0 if 8 <= now.hour <= 16 else 0.0
            american_session = 1.0 if 16 <= now.hour <= 24 else 0.0
            
            # –û—Å–æ–±—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞
            weekend_factor = 0.5 if now.weekday() >= 5 else 1.0
            
            return [
                hour_sin, hour_cos, day_of_week_sin, day_of_week_cos,
                asian_session, european_session, american_session, weekend_factor
            ]
        except:
            return [0.0] * 8